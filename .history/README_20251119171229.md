# Fauteuil Roulant Intelligent (E-WheelChAIr)

**Un environnement de simulation pour la navigation sociale d'un fauteuil roulant intelligent utilisant le Reinforcement Learning et le Behavioral Cloning.**

---

## Table des Matières
- [Description](#description)
- [Fonctionnalités](#fonctionnalités)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Configuration](#configuration)
- [Récompenses et Comportements Sociaux](#récompenses-et-comportements-sociaux)
  - [Récompenses de Base](#récompenses-de-base)
  - [Zones Sociales](#zones-sociales)
  - [Situations de Groupe](#situations-de-groupe)
  - [Exemples de Comportements](#exemples-de-comportements)
  - [Paramètres Clés](#paramètres-clés)
- [Structure du Projet](#structure-du-projet)
- [Visualisation](#visualisation)
- [Contribution](#contribution)
- [Licence](#licence)
- [Auteurs](#auteurs)

---

## Description

Projet de simulation d'un fauteuil roulant intelligent capable de naviguer dans un environnement 2D avec obstacles et humains (statiques/dynamiques). Utilise Gymnasium et Pygame pour la simulation et visualisation.

---

## Fonctionnalités

- Simulation 2D avec obstacles et humains
- Groupes d'humains convergents/divergents
- Zones sociales avec système de récompenses
- Détection de situations critiques
- Visualisation temps réel
- Compatible avec RL et Behavioral Cloning

---

## Installation

### Prérequis
- Python 3.10+
- Git
- Bibliothèques: `gymnasium`, `pygame`, `numpy`

### Étapes

1. Cloner le dépôt:
```bash
git clone https://github.com/RicTic93/Social_robotics.git
cd Social_robotics/project_fauteuil_RL
```

2. Installer les dépendances:
```bash
pip install -r requirements.txt
```

3. Utilisation
### Simulation basique:
```bash
python agent_simple_policy.py
```

4. Generer des démonstrations
```bash
python agent_simple_policy.py --num_demos 50
```
5. Configuration
Configuration dans config.py:
```python
config = {
    'num_objects': 6,
    'dynamic_humans_count': 4,
    'static_groups': [
        {
            'count': 3,
            'formation': 'converging',
            'center_pos': [3.0, 5.0],
            'radius': 1.0
        }
    ],
    'social_distance': 1.5,
    'max_steps': 500
}
```
6. Récompenses et Comportements Sociaux\

Recompenses de base

| Événement               | Récompense | Description          |
|-------------------------|------------|----------------------|
| Atteindre le but        | +10        | Objectif atteint     |
| Collision humain        | -10        | Termine l'épisode     |
| Collision obstacle      | -3         | Termine l'épisode     |

Sociales zones
| Zone       | Distance (m) | Récompense | Description               |
|------------|--------------|------------|---------------------------|
| Intime     | < 0.4        | -5         | Zone intrusive            |
| Personnelle| 0.4-1.2      | -2         | Zone de confort           |
| Sociale    | 1.2-3.6      | 0          | Interaction normale       |
| Publique   | ≥ 3.6        | 0          | Aucune restriction        |

Situations de Groupe :
- Convergente: Pénalité -5 si passage entre humains
- Face-à-face: Pénalité -5
- Arc/Cercle: Pénalité -5
- Dynamiques: Même système que statiques

7. Licence
Ce projet est sous licence Apache 2.0.
8. 
 Auteurs
